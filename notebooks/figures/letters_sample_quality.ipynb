{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce6f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import model.sdes as sdes\n",
    "import model.generate as generate\n",
    "import model.table_dnn as table_dnn\n",
    "import model.util as model_util\n",
    "from plot.plot import plot_mnist_digits\n",
    "from analysis.fid import compute_fid\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68a485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "font_list = font_manager.findSystemFonts(fontpaths=[\"/gstore/home/tsenga5/modules/fonts\"])\n",
    "for font in font_list:\n",
    "    font_manager.fontManager.addfont(font)\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"font.size\": 13,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.family\": \"Roboto\",\n",
    "    \"font.weight\": \"bold\",\n",
    "    \"svg.fonttype\": \"none\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df22d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9896c40d",
   "metadata": {},
   "source": [
    "### Define constants and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cca45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_base_path = \"/gstore/data/resbioai/tsenga5/branched_diffusion/models/trained_models/\"\n",
    "\n",
    "branched_model_path = os.path.join(models_base_path, \"letters_continuous_allletters/2/epoch_300_ckpt.pth\")\n",
    "label_guided_model_path = os.path.join(models_base_path, \"letters_continuous_allletters_labelguided/1/epoch_100_ckpt.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "255b2c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the branches\n",
    "letters = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n",
    "class_to_letter = dict(enumerate(letters))\n",
    "letter_to_class = {v : k for k, v in class_to_letter.items()}\n",
    "\n",
    "classes = [letter_to_class[l] for l in letters]\n",
    "branch_defs = [(('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'), 0.5235235235235235, 1), (('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'X', 'Y', 'Z'), 0.5165165165165165, 0.5235235235235235), (('B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'X', 'Y', 'Z'), 0.5115115115115115, 0.5165165165165165), (('B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'X', 'Y', 'Z'), 0.4944944944944945, 0.5115115115115115), (('I', 'J'), 0.4794794794794795, 0.4944944944944945), (('B', 'C', 'D', 'E', 'F', 'G', 'H', 'K', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'X', 'Y', 'Z'), 0.4724724724724725, 0.4944944944944945), (('B', 'C', 'D', 'E', 'G', 'H', 'K', 'M', 'N', 'O', 'Q', 'R', 'S', 'U', 'X', 'Z'), 0.45645645645645644, 0.4724724724724725), (('F', 'P', 'T', 'V', 'Y'), 0.4364364364364364, 0.4724724724724725), (('B', 'C', 'D', 'E', 'G', 'H', 'K', 'N', 'O', 'Q', 'R', 'S', 'U', 'X', 'Z'), 0.4174174174174174, 0.45645645645645644), (('B', 'C', 'D', 'E', 'G', 'H', 'K', 'N', 'O', 'Q', 'R', 'S', 'X', 'Z'), 0.4134134134134134, 0.4174174174174174), (('B', 'D', 'G', 'H', 'K', 'N', 'O', 'Q', 'R', 'S', 'X', 'Z'), 0.4094094094094094, 0.4134134134134134), (('F', 'T', 'V', 'Y'), 0.4024024024024024, 0.4364364364364364), (('B', 'D', 'G', 'H', 'K', 'O', 'Q', 'R', 'S', 'X', 'Z'), 0.3863863863863864, 0.4094094094094094), (('B', 'G', 'H', 'K', 'O', 'Q', 'R', 'S', 'X', 'Z'), 0.3813813813813814, 0.3863863863863864), (('B', 'G', 'H', 'O', 'Q', 'R', 'S', 'X', 'Z'), 0.3733733733733734, 0.3813813813813814), (('F', 'T', 'Y'), 0.36036036036036034, 0.4024024024024024), (('C', 'E'), 0.3563563563563564, 0.4134134134134134), (('T', 'Y'), 0.3533533533533533, 0.36036036036036034), (('B', 'R', 'S', 'X', 'Z'), 0.35135135135135137, 0.3733733733733734), (('G', 'H', 'O', 'Q'), 0.34134134134134136, 0.3733733733733734), (('B', 'S', 'X', 'Z'), 0.32232232232232233, 0.35135135135135137), (('B', 'S', 'X'), 0.27627627627627627, 0.32232232232232233), (('G', 'H', 'O'), 0.26426426426426425, 0.34134134134134136), (('G', 'O'), 0.25725725725725723, 0.26426426426426425), (('S', 'X'), 0.15615615615615616, 0.27627627627627627), (('W',), 0, 0.5235235235235235), (('A',), 0, 0.5165165165165165), (('L',), 0, 0.5115115115115115), (('J',), 0, 0.4794794794794795), (('I',), 0, 0.4794794794794795), (('M',), 0, 0.45645645645645644), (('P',), 0, 0.4364364364364364), (('U',), 0, 0.4174174174174174), (('N',), 0, 0.4094094094094094), (('V',), 0, 0.4024024024024024), (('D',), 0, 0.3863863863863864), (('K',), 0, 0.3813813813813814), (('F',), 0, 0.36036036036036034), (('E',), 0, 0.3563563563563564), (('C',), 0, 0.3563563563563564), (('Y',), 0, 0.3533533533533533), (('T',), 0, 0.3533533533533533), (('R',), 0, 0.35135135135135137), (('Q',), 0, 0.34134134134134136), (('Z',), 0, 0.32232232232232233), (('B',), 0, 0.27627627627627627), (('H',), 0, 0.26426426426426425), (('G',), 0, 0.25725725725725723), (('O',), 0, 0.25725725725725723), (('S',), 0, 0.15615615615615616), (('X',), 0, 0.15615615615615616)]\n",
    "\n",
    "branch_defs = [\n",
    "    (tuple(map(lambda l: letter_to_class[l], trip[0])), trip[1], trip[2])\n",
    "    for trip in branch_defs\n",
    "]\n",
    "\n",
    "input_shape = (16,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0640440",
   "metadata": {},
   "outputs": [],
   "source": [
    "sde = sdes.VariancePreservingSDE(0.1, 20, input_shape)\n",
    "t_limit = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e9253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"/gstore/home/tsenga5/branched_diffusion/figures/letters_sample_quality\"\n",
    "\n",
    "os.makedirs(out_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f058fa4",
   "metadata": {},
   "source": [
    "### Create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ef8d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LetterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        data_path = \"/gstore/data/resbioai/tsenga5/branched_diffusion/data/letter_recognition/letter-recognition.data\"\n",
    "        \n",
    "        data = []\n",
    "        targets = []\n",
    "        with open(data_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                tokens = line.strip().split(\",\")\n",
    "                targets.append(tokens[0])\n",
    "                data.append(np.array(list(map(int, tokens[1:]))))\n",
    "        self.data = np.stack(data)\n",
    "        self.targets = np.array([letter_to_class[l] for l in targets])\n",
    "        \n",
    "        # Center/normalize the data\n",
    "        self.data = (self.data - np.mean(self.data, axis=0, keepdims=True)) / \\\n",
    "            np.std(self.data, axis=0, keepdims=True)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.data[index]).float(), self.targets[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "dataset = LetterDataset()\n",
    "\n",
    "# Limit classes\n",
    "inds = np.isin(dataset.targets, classes)\n",
    "dataset.data = dataset.data[inds]\n",
    "dataset.targets = dataset.targets[inds]\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "input_shape = next(iter(data_loader))[0].shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51fbc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this is currently rather inefficient; a decision-tree-style structure\n",
    "# would be better\n",
    "\n",
    "def class_time_to_branch(c, t):\n",
    "    \"\"\"\n",
    "    Given a class and a time (both scalars), return the\n",
    "    corresponding branch index.\n",
    "    \"\"\"\n",
    "    for i, branch_def in enumerate(branch_defs):\n",
    "        if c in branch_def[0] and t >= branch_def[1] and t <= branch_def[2]:\n",
    "            return i\n",
    "    raise ValueError(\"Undefined class and time\")\n",
    "        \n",
    "def class_time_to_branch_tensor(c, t):\n",
    "    \"\"\"\n",
    "    Given tensors of classes and a times, return the\n",
    "    corresponding branch indices as a tensor.\n",
    "    \"\"\"\n",
    "    return torch.tensor([\n",
    "        class_time_to_branch(c_i, t_i) for c_i, t_i in zip(c, t)\n",
    "    ], device=DEVICE)\n",
    "\n",
    "def class_to_class_index_tensor(c):\n",
    "    \"\"\"\n",
    "    Given a tensor of classes, return the corresponding class indices\n",
    "    as a tensor.\n",
    "    \"\"\"\n",
    "    return torch.argmax(\n",
    "        (c[:, None] == torch.tensor(classes, device=c.device)).int(), dim=1\n",
    "    ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f55c8b",
   "metadata": {},
   "source": [
    "### Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efedd4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "branched_model = model_util.load_model(\n",
    "    table_dnn.MultitaskTabularNet, branched_model_path\n",
    ").to(DEVICE)\n",
    "\n",
    "label_guided_model = model_util.load_model(\n",
    "    table_dnn.LabelGuidedTabularNet, label_guided_model_path\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bd65a8",
   "metadata": {},
   "source": [
    "### Sample letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f7c9fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling class: 0\n",
      "Sampling class: 1\n",
      "Sampling class: 2\n",
      "Sampling class: 3\n",
      "Sampling class: 4\n",
      "Sampling class: 5\n",
      "Sampling class: 6\n",
      "Sampling class: 7\n",
      "Sampling class: 8\n",
      "Sampling class: 9\n",
      "Sampling class: 10\n",
      "Sampling class: 11\n",
      "Sampling class: 12\n",
      "Sampling class: 13\n",
      "Sampling class: 14\n",
      "Sampling class: 15\n",
      "Sampling class: 16\n",
      "Sampling class: 17\n",
      "Sampling class: 18\n",
      "Sampling class: 19\n",
      "Sampling class: 20\n",
      "Sampling class: 21\n",
      "Sampling class: 22\n",
      "Sampling class: 23\n",
      "Sampling class: 24\n",
      "Sampling class: 25\n"
     ]
    }
   ],
   "source": [
    "# Sample digits of each class from branched model\n",
    "branched_samples = {}\n",
    "for class_to_sample in classes:\n",
    "    print(\"Sampling class: %s\" % class_to_sample)\n",
    "    samples = generate.generate_continuous_branched_samples(\n",
    "        branched_model, sde, class_to_sample, class_time_to_branch_tensor,\n",
    "        sampler=\"pc\", t_limit=t_limit, num_samples=1000\n",
    "    ).cpu().numpy()\n",
    "    branched_samples[class_to_sample] = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7395b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample digits of each class from label-guided model\n",
    "# label_guided_samples = {}\n",
    "# for class_to_sample in classes:\n",
    "#     print(\"Sampling class: %s\" % class_to_sample)\n",
    "#     samples = generate.generate_continuous_label_guided_samples(\n",
    "#         label_guided_model, sde, class_to_sample, class_to_class_index_tensor,\n",
    "#         sampler=\"pc\", t_limit=t_limit, num_samples=1000\n",
    "#     ).cpu().numpy()\n",
    "#     label_guided_samples[class_to_sample] = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb232f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling class: 0\n",
      "Sampling class: 1\n",
      "Sampling class: 2\n",
      "Sampling class: 3\n",
      "Sampling class: 4\n",
      "Sampling class: 5\n",
      "Sampling class: 6\n",
      "Sampling class: 7\n",
      "Sampling class: 8\n",
      "Sampling class: 9\n",
      "Sampling class: 10\n",
      "Sampling class: 11\n",
      "Sampling class: 12\n",
      "Sampling class: 13\n",
      "Sampling class: 14\n",
      "Sampling class: 15\n",
      "Sampling class: 16\n",
      "Sampling class: 17\n",
      "Sampling class: 18\n",
      "Sampling class: 19\n",
      "Sampling class: 20\n",
      "Sampling class: 21\n",
      "Sampling class: 22\n",
      "Sampling class: 23\n",
      "Sampling class: 24\n",
      "Sampling class: 25\n"
     ]
    }
   ],
   "source": [
    "# Sample digits from the original dataset\n",
    "true_samples = {}\n",
    "for class_to_sample in classes:\n",
    "    print(\"Sampling class: %s\" % class_to_sample)\n",
    "    inds = np.where(dataset.targets == class_to_sample)[0]\n",
    "    sample_inds = np.random.choice(inds, size=700, replace=False)\n",
    "    samples = dataset.data[sample_inds]\n",
    "    true_samples[class_to_sample] = samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5426e43",
   "metadata": {},
   "source": [
    "### Show true/predicted distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a81c1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the overall distribution of Wasserstein distance between feature distributions,\n",
    "# # both between true/predicted distributions, and between true predictions\n",
    "# num_features = input_shape[0]\n",
    "# true_pred_dists = {}\n",
    "# true_true_dists = {}\n",
    "# for i in range(num_features):\n",
    "#     for class_to_sample in classes:\n",
    "#         true = true_samples[class_to_sample][:, i]\n",
    "#         generated = branched_samples[class_to_sample][:, i]\n",
    "#         true_pred_dists[(class_to_sample, i)] = scipy.stats.wasserstein_distance(true, generated)\n",
    "    \n",
    "#     for c_i1 in range(len(classes)):\n",
    "#         for c_i2 in range(c_i1):\n",
    "#             c1, c2 = classes[c_i1], classes[c_i2]\n",
    "#             true_1, true_2 = true_samples[c1][:, i], true_samples[c2][:, i]\n",
    "#             true_true_dists[(c1, c2, i)] = scipy.stats.wasserstein_distance(true_1, true_2)\n",
    "        \n",
    "# num_bins = 30\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# true_pred_vals, true_true_vals = np.array(list(true_pred_dists.values())), np.array(list(true_true_dists.values()))\n",
    "# all_vals = np.concatenate([true_pred_vals, true_true_vals])\n",
    "# bins = np.linspace(np.min(all_vals), np.max(all_vals), num_bins)\n",
    "# ax.hist(true_pred_vals, bins=bins, label=\"True vs generated features\", alpha=0.5, density=True)\n",
    "# ax.hist(true_true_vals, bins=bins, label=\"True vs true features\", alpha=0.5, density=True)\n",
    "# ax.set_title(\"Distribution of Wasserstein distance between features\")\n",
    "# ax.set_xlabel(\"Wasserstein distance\")\n",
    "# plt.show()\n",
    "# fig.savefig(\n",
    "#     os.path.join(out_path, \"letters_feature_distance_all.svg\"),\n",
    "#     format=\"svg\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b2e8092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Plot some example distributions of all features for certain classes\n",
    "# mean_true_pred_dists = {c : [] for c in classes}\n",
    "# for (c, _), dist in true_pred_dists.items():\n",
    "#     mean_true_pred_dists[c].append(dist)\n",
    "# for c, vals in mean_true_pred_dists.items():\n",
    "#     mean_true_pred_dists[c] = np.mean(vals)\n",
    "    \n",
    "# num_cols = 4\n",
    "# num_rows = int(np.ceil(num_features / num_cols))\n",
    "# num_bins = 30\n",
    "    \n",
    "# for class_to_show in sorted(mean_true_pred_dists.keys(), key=lambda k: mean_true_pred_dists[k])[:3]:\n",
    "#     fig, ax = plt.subplots(ncols=num_cols, nrows=num_rows, figsize=(num_cols * 5, num_rows * 5))\n",
    "#     for i in range(num_features):\n",
    "#         r, c = i // num_cols, i % num_cols\n",
    "#         true = np.ravel(true_samples[class_to_show][:, i])\n",
    "#         generated = np.ravel(branched_samples[class_to_show][:, i])\n",
    "#         all_vals = np.concatenate([true, generated])\n",
    "#         bins = np.linspace(np.min(all_vals), np.max(all_vals), num_bins)\n",
    "#         ax[r][c].hist(true, bins=bins, color=\"royalblue\", label=\"True\", density=True, alpha=0.5)\n",
    "#         ax[r][c].hist(generated, bins=bins, color=\"darkorange\", label=\"Generated\", density=True, alpha=0.5)\n",
    "#         ax[r][c].set_title(\"Feature %d\" % (i + 1))\n",
    "#     ax[0][0].legend()\n",
    "#     fig.suptitle(\"Class %s\" % class_to_letter[class_to_show])\n",
    "#     plt.show()\n",
    "#     fig.savefig(\n",
    "#         os.path.join(out_path, \"letters_feature_distance_%s.svg\" % class_to_letter[class_to_show]),\n",
    "#         format=\"svg\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28b220fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Plot some example distributions of specific features for multiple classes\n",
    "# num_bins = 30\n",
    "# for (c1, c2, i), t_t_val in true_true_dists.items():\n",
    "#     p_t_val_1, p_t_val_2 = true_pred_dists[(c1, i)], true_pred_dists[(c2, i)]\n",
    "#     if t_t_val > 2 and p_t_val_1 < 0.2 and p_t_val_2 < 0.2:\n",
    "#         fig, ax = plt.subplots(figsize=(8, 8))\n",
    "#         true_1 = np.ravel(true_samples[c1][:, i])\n",
    "#         generated_1 = np.ravel(branched_samples[c1][:, i])\n",
    "#         true_2 = np.ravel(true_samples[c2][:, i])\n",
    "#         generated_2 = np.ravel(branched_samples[c2][:, i])\n",
    "#         all_vals = np.concatenate([true_1, generated_1, true_2, generated_2])\n",
    "#         bins = np.linspace(np.min(all_vals), np.max(all_vals), num_bins)\n",
    "#         ax.hist(\n",
    "#             true_1, bins=bins, color=\"royalblue\", label=(\"True %s\" % class_to_letter[c1]), density=True, alpha=0.5\n",
    "#         )\n",
    "#         ax.hist(\n",
    "#             generated_1, bins=bins, color=\"blueviolet\", label=(\"Generated %s\" % class_to_letter[c1]), density=True, alpha=0.5\n",
    "#         )\n",
    "#         ax.hist(\n",
    "#             true_2, bins=bins, color=\"darkorange\", label=(\"True %s\" % class_to_letter[c2]), density=True, alpha=0.5\n",
    "#         )\n",
    "#         ax.hist(\n",
    "#             generated_2, bins=bins, color=\"goldenrod\", label=(\"Generated %s\" % class_to_letter[c2]), density=True, alpha=0.5\n",
    "#         )\n",
    "#         ax.set_title(\"Feature %d, %s vs %s\" % (i + 1, class_to_letter[c1], class_to_letter[c2]))\n",
    "#         ax.legend()\n",
    "#         plt.show()\n",
    "#         fig.savefig(\n",
    "#             os.path.join(out_path, \"letters_feature_distance_%s_%s.svg\" % (class_to_letter[c1], class_to_letter[c2])),\n",
    "#             format=\"svg\"\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ced5bb7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show true and predicted correlations between features\n",
    "# true_corrs = np.empty((len(classes), num_features, num_features))\n",
    "# generated_corrs = np.empty((len(classes), num_features, num_features))\n",
    "# for c_i, c in enumerate(classes):\n",
    "#     true = true_samples[c]\n",
    "#     generated = branched_samples[c]\n",
    "#     for i in range(num_features):\n",
    "#         true_corrs[c_i, i, i] = 1\n",
    "#         generated_corrs[c_i, i, i] = 1\n",
    "#         for j in range(i):\n",
    "#             true_corrs[c_i, i, j] = scipy.stats.pearsonr(true[:, i], true[:, j])[0]\n",
    "#             true_corrs[c_i, j, i] = true_corrs[c_i, i, j]\n",
    "#             generated_corrs[c_i, i, j] = scipy.stats.pearsonr(generated[:, i], generated[:, j])[0]\n",
    "#             generated_corrs[c_i, j, i] = generated_corrs[c_i, i, j]\n",
    "            \n",
    "# for c_i in np.argsort(np.mean(np.abs(true_corrs - generated_corrs), axis=(1, 2)))[:26]:\n",
    "#     fig, ax = plt.subplots(ncols=3, figsize=(20, 10))\n",
    "#     ax[0].imshow(true_corrs[c_i], cmap=\"Blues\", vmin=0, vmax=1)\n",
    "#     ax[0].set_title(\"Real correlations\")\n",
    "#     ax[1].imshow(generated_corrs[c_i], cmap=\"Blues\", vmin=0, vmax=1)\n",
    "#     ax[1].set_title(\"Sample correlations\")\n",
    "#     ax[2].imshow(np.abs(true_corrs[c_i] - generated_corrs[c_i]), cmap=\"Blues\", vmin=0, vmax=1)\n",
    "#     ax[2].set_title(\"Absolute difference in correlations\")\n",
    "#     fig.suptitle(\"Class %s\" % class_to_letter[classes[c_i]])\n",
    "#     plt.show()\n",
    "#     fig.savefig(\n",
    "#         os.path.join(out_path, \"letters_feature_corr_%s.svg\" % class_to_letter[classes[c_i]]),\n",
    "#         format=\"svg\"\n",
    "#     )\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 1))\n",
    "ax.imshow(np.vstack((np.linspace(0, 1, 256), np.linspace(0, 1, 256))), aspect=\"auto\", cmap=\"Blues\")\n",
    "ax.set_xticks(np.linspace(0, 256, 11))\n",
    "ax.set_xticklabels([round(x, 1) for x in np.linspace(0, 1, 11)])\n",
    "ax.set_yticks([])\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    os.path.join(out_path, \"letters_feature_corr_colorbar.svg\"), format=\"svg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5206c88c",
   "metadata": {},
   "source": [
    "### Compute FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca83ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute FID scores\n",
    "fid_scores = {}\n",
    "for class_to_sample in classes:\n",
    "    print(\"FID of %d\" % class_to_sample)\n",
    "    branched = branched_samples[class_to_sample]\n",
    "    label_guided = label_guided_samples[class_to_sample]\n",
    "    true = true_samples[class_to_sample]\n",
    "    branched_fid = compute_fid(branched, true)\n",
    "    label_guided_fid = compute_fid(label_guided, true)\n",
    "    fid_scores[class_to_sample] = (branched_fid, label_guided_fid)\n",
    "    print(\"Branched FID: %.4f\" % branched_fid)\n",
    "    print(\"Label-guided FID: %.4f\" % label_guided_fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc81176",
   "metadata": {},
   "outputs": [],
   "source": [
    "branched_vals, linear_vals = [fid_scores[c][0] for c in classes], [fid_scores[c][1] for c in classes]\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bar_width = 0.4\n",
    "x = np.arange(len(fid_scores))\n",
    "ax.bar(\n",
    "    x, branched_vals, bar_width, label=\"Branched\", color=\"royalblue\"\n",
    ")\n",
    "ax.bar(\n",
    "    x + bar_width, linear_vals, bar_width, label=\"Label-guided (linear)\", color=\"darkorange\"\n",
    ")\n",
    "ax.set_xticks(x + (bar_width / 2), labels=[class_to_letter[c] for c in classes])\n",
    "ax.set_xlabel(\"Letter class\")\n",
    "ax.set_ylabel(\"FID\")\n",
    "ax.set_title(\"Fr√©chet inception distance between true and generated letters\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    os.path.join(out_path, \"letters_fid.svg\"),\n",
    "    format=\"svg\"\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(branched_vals, linear_vals)\n",
    "ax.set_xlabel(\"Branched\")\n",
    "ax.set_ylabel(\"Label-guided (linear)\")\n",
    "max_val = np.max(branched_vals + linear_vals)\n",
    "ax.plot((0, max_val), (0, max_val), \"--\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
